{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traffic Predict System\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this project, we try to use some traffic data to predict the traffic jam in a certain area. In order to predict such phenomenon, we need to build a model based on some data that we can collect. The first data we came up with was the real time traffic count in the area. As we searching for the real time traffic data, we realize that it's almost impossible to find any data in real time. Most of the free data, of the traffic count, is in statical format or historical and aggregated. \n",
    "\n",
    "### Goal\n",
    "Specifically, our goal is to predict the approximate alert count(or *alert level*) given a set of hourly features as input. In order to do that, we extract several features from the raw data we crawled, and feed them into a CNN model with PyTorch. We make predictions with this model and get a satisfying accurancy. Finally we present our results with a visulization system using D3.js \n",
    "\n",
    "## Data Source - Waze\n",
    "Then, the waze.com came in to our sight.Waze is GPS navigation software that works on smartphones and tablets with GPS support. It provides turn-by-turn navigation information and user-submitted travel times and route details, while downloading location-dependent information over a mobile telephone network. Waze describes its app as a community-driven GPS navigation app. It encourages users to post anything that would slow down the traffic or anything need to be care about on the map.Also this app will show any active drivers/users on the map. If we can collect itï¼Œthen we can start our project. Luckily, besides the app, WAZE also provides a web live map, which shows exactually the same thing as the app shows. By collecting data on the web live map,we get the initial data we need.\n",
    "\n",
    "### The web live map\n",
    "![live map](https://i.imgur.com/aDqi8JK.jpg \"Live map\")\n",
    "\n",
    "### List of data collected from waze\n",
    "#### Alert\n",
    "Alert is a data point submitted by the active users. An alert may belong to different category, For example construction site, car accident or even \"Police Nearby\". We believe that the more alerts on the map, the worse the traffic is.\n",
    "#### User Location\n",
    "We also collect the active users on the map. We use the user lcoation to simulate the traffic density on the map.\n",
    "#### User Speed\n",
    "Besides users'location, we also collect the users' speed on the road.\n",
    "\n",
    "### Problem\n",
    "The only problem is that the data point is too sparse, there should be far more traffic thant it shows on the app. So in order to make the data less sparse, we need some method to aggregate our data. What we find is to use the census tracts to aggregrate our data.\n",
    "\n",
    "### Census Tracts\n",
    "Census Tracts are small, relatively permanent statistical subdivisions of a county or equivalent entity that are updated by local participants prior to each decennial census as part of the Census Bureau's Participant Statistical Areas Program.  The Census Bureau delineates census tracts in situations where no local participant existed or where state, local, or tribal governments declined to participate. The primary purpose of census tracts is to provide a stable set of geographic units for the presentation of statistical data. Census tracts generally have a population size between 1,200 and 8,000 people, with an optimum size of 4,000 people. Census tract boundaries generally follow visible and identifiable features.  They may follow nonvisible legal boundaries, such as minor civil division (MCD) or incorporated place boundaries in some states and situations, to allow for census-tract-to-governmental-unit relationships where the governmental boundaries tend to remain unchanged between censuses.  \n",
    "\n",
    "### Demographic Data\n",
    "We also collect a bunch of demographic data associate with each census tracts, for example the resident count, the average commuter time to work place of residents and the area of the census tracts. We believe it can help our model to get better correctness.\n",
    "\n",
    "### Weather Data\n",
    "It is common sense that the weather does affect the traffic. So we also collect it as the input variable of our model. Sometimes, a city has mulitiple weather stations, so we try to mapping our census tracts with the weather data from the nearest weather station. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practical Datascience Trainer\n",
    "Here we will first load data, which is crawled from Waze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.2.0_4'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import modules\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torchvision import datasets, transforms\n",
    "from torch.nn.utils import clip_grad_norm\n",
    "\n",
    "from logger import ModelLogger, getLogger\n",
    "from meter import AverageMeter\n",
    "from helper import to_tensor, to_variable, BaseTrainer\n",
    "import helper\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "log = getLogger()\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Args\n",
    "\n",
    "In this part, we provide a clean way to tune hyperparameters. \n",
    "- first part is related with training process.\n",
    "- if you want to load pretrained model, set is_load to True.\n",
    "- It contains 3 mode: 'train', 'infer', 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {}\n",
    "args['epochs'] = 5\n",
    "args['max_iter'] = -1\n",
    "args['val_frac'] = 0.1\n",
    "args['batch_size'] = 16\n",
    "args['val_batch_size'] = 32\n",
    "args['test_batch_size'] = 1\n",
    "args['num_workers'] = 0\n",
    "args['clip'] = 0.05\n",
    "args['lr'] = 0.001\n",
    "args['wd'] = 2e-5\n",
    "args['shuffle'] = True\n",
    "\n",
    "args['display_interval'] = 100\n",
    "args['calc_acc_interval'] = 1\n",
    "args['val_interval'] = 1\n",
    "args['val_display_interval'] = 50\n",
    "\n",
    "args['test_interval'] = 1000\n",
    "args['save_threshold'] = 300\n",
    "\n",
    "# directory relatied\n",
    "args['save_directory'] = 'output'\n",
    "args['is_log'] = False\n",
    "args['logdir'] = './logs'\n",
    "args['best_model'] = 'model_1525721489_0.8618.t7'\n",
    "args['cuda'] = torch.cuda.is_available()\n",
    "\n",
    "args['is_load'] = False\n",
    "args['mode'] = 'train' # 'train', 'infer', 'test'\n",
    "args = helper.parser(args)\n",
    "# %lprun -f Trainer.train -u 1 main(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data\n",
    "\n",
    "The original data crawled from Wave is orgainzed as per hour and per Census Tract, which is not suitable for our machine learning algorithm. We want to combine Census Tracts and add some useful static Tract data in it. Besides that, normalize is a really important technique, which should be applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_pickle('./Chicage_data.p')\n",
    "static = np.load('./Chicage_static.npy')\n",
    "n = []\n",
    "for d in df.groupby(['order']):\n",
    "    # for every hour, their is an distinct 'order' column behaves as 'id'\n",
    "    tmp = d[1].sort_values(['ct']).drop(['ct', 'order', 'outlook', 'alert_count'], axis=1)\n",
    "    tmp['time'] = tmp['time'].dt.hour\n",
    "    n.append(tmp)\n",
    "\n",
    "# convert list to np.ndarray\n",
    "ns = np.array([np.asarray(i) for i in n]).transpose((0, 2, 1))\n",
    "\n",
    "# add part of static features\n",
    "ns = np.array([np.concatenate([n, static[:,[1, 3, -1]].T], axis=0) for n in ns])\n",
    "# normalize\n",
    "ns = (ns - ns.mean(axis=-1, keepdims=True)) / (ns.max(axis=-1, keepdims=True) + 1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Label\n",
    "Here we define our label is: the alert_level of the whole city. It is separated to 5 level:\n",
    "- Level 1: alert count from 1~99\n",
    "- Level 2: alert count from 100~199\n",
    "- Level 3: alert count from 200~249\n",
    "- Level 4: alert count from 250~350\n",
    "- Level 5: alert count from 351~500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array([np.asarray(d[1]['alert_count']) for d in df.groupby(['order'])])\n",
    "labels = labels.sum(-1)\n",
    "level_labels = []\n",
    "for i, l in enumerate(labels):\n",
    "    if l > 500:\n",
    "        level_labels.append(4)\n",
    "    elif l > 350:\n",
    "        level_labels.append(3)\n",
    "    elif l > 200:\n",
    "        level_labels.append(2)\n",
    "    elif l > 100:\n",
    "        level_labels.append(1)\n",
    "    else:\n",
    "        level_labels.append(0)\n",
    "level_labels = np.array(level_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n5gIgAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f96575190f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(level_labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dev_data = ns # data_count, feature_size, blocks\n",
    "raw_dev_label = level_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlockDataset(Dataset):\n",
    "    def __init__(self, datas, labels, test=False):\n",
    "        super().__init__()\n",
    "        if test or labels is None:\n",
    "            labels = [np.zeros(1, dtype=np.int32) for _ in datas]\n",
    "\n",
    "        self.datas = [to_tensor(d) for d in datas]\n",
    "        self.labels = to_tensor(labels)\n",
    "        self.len = len(datas)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.datas[index], self.labels[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Model\n",
    "The model is really simple, but it works for the dataset.\n",
    "\n",
    "First is a sequence of feature detector, followed by a classifier. In feature detector, we use 3 1D Convolution Layer, LeakyReLU and MaxPooling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, in_channels=3, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.seq = nn.Sequential(\n",
    "            nn.Conv1d(in_channels, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2),\n",
    "            nn.Conv1d(256, 256, kernel_size=3, stride=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2),\n",
    "            nn.Conv1d(256, 256, kernel_size=3, stride=1),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(256, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        features =  self.seq(input)\n",
    "        features = torch.mean(features, dim=-1)\n",
    "        return self.classifier(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataLoader\n",
    "In Pytorch, the data is often got from dataloader, here we define train loader and validation loader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloaders(args, Dataset, train, labels, test = None):\n",
    "    kwargs = {'num_workers': args.num_workers, 'pin_memory': True} if args.cuda else {}\n",
    "\n",
    "    train_dataset = Dataset(train, labels)\n",
    "    train_loader = DataLoader(\n",
    "        dataset=train_dataset,\n",
    "        batch_size=args.batch_size,\n",
    "        shuffle=args.shuffle,\n",
    "        **kwargs)\n",
    "    val_dataset = Dataset(train, labels)\n",
    "    val_loader = DataLoader(\n",
    "        dataset=val_dataset,\n",
    "        batch_size=args.val_batch_size,\n",
    "        shuffle=False,\n",
    "        **kwargs)\n",
    "        \n",
    "    train_size = len(train_dataset)\n",
    "    val_size = len(val_dataset)\n",
    "    return {\n",
    "        'train_loader': train_loader,\n",
    "        'train_size': train_size,\n",
    "        'val_loader': val_loader,\n",
    "        'val_size': val_size,\n",
    "        'test_loader': None, \n",
    "        'test_size': 0\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class Trainer(BaseTrainer):\n",
    "    def __init__(self, model, optimizer, scheduler, loss_fn, loader, args):\n",
    "        super().__init__(model, optimizer, scheduler, loss_fn, loader, args)\n",
    "    \n",
    "    def accuracy(self, pred, label_masked):\n",
    "        pred = pred.data.cpu().numpy().argmax(-1)\n",
    "        acc = np.abs(pred == label_masked.cpu().numpy()).sum() / label_masked.size(0)\n",
    "        return float(acc)\n",
    "    \n",
    "    def train(self, epoch):\n",
    "        batch_time = AverageMeter()\n",
    "        data_time = AverageMeter()\n",
    "        losses = AverageMeter()\n",
    "        correct = AverageMeter()\n",
    "\n",
    "        self.model.train()\n",
    "        end = time.time()\n",
    "    \n",
    "        for batch_idx, (features, labels) in enumerate(self.train_loader):\n",
    "            self.optimizer.zero_grad()\n",
    "            # measure data loading time\n",
    "            data_time.update(time.time() - end)\n",
    "            \n",
    "            prediction = self.model(to_variable(features).float())\n",
    "            loss = self.loss_fn(prediction, to_variable(labels))\n",
    "            loss.backward()\n",
    "            losses.update(loss.data.cpu()[0]/features.size(0)*0.6, features.size(0))\n",
    "            # compute gradient and take a baby step\n",
    "            clip_grad_norm(self.model.parameters(), args.clip)\n",
    "            self.optimizer.step()\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            def post_print():\n",
    "                \"\"\"\n",
    "                It calculates accuracy and print pretty format log\n",
    "                \"\"\"\n",
    "                step = epoch * len(self.train_loader) + losses.count // self.args.batch_size\n",
    "\n",
    "                if batch_idx == 0:\n",
    "                    return True\n",
    "\n",
    "                if batch_idx % self.args.calc_acc_interval == 0:\n",
    "                    # calculate acc\n",
    "                    curr_correct = self.accuracy(prediction, labels)\n",
    "                    correct.update(curr_correct, features.size(0))\n",
    "                    self.logger.log_train_info(losses.avg, correct.avg, step)\n",
    "\n",
    "                if batch_idx % self.args.display_interval == 0:\n",
    "                    # display and log\n",
    "                    info = 'Epoch: [{0}][{1}/{2}]\\tTime {batch_time:2.2f}m\\tLoss {loss.val:.4f}[{loss.window_avg:.4f}]\\t'.format(\n",
    "                              epoch,\n",
    "                              batch_idx,\n",
    "                              len(self.train_loader),\n",
    "                              batch_time=batch_time.sum / 60,\n",
    "                              data_time=data_time,\n",
    "                              loss=losses)\n",
    "                    if batch_idx % self.args.calc_acc_interval == 0:\n",
    "                        acc_info = 'Acc {train_acc.val:.4f}[{train_acc.window_avg:.4f}]'.format(train_acc=correct)\n",
    "                        info += acc_info\n",
    "                    log.info(info)\n",
    "                return True\n",
    "            if not post_print():\n",
    "                break\n",
    "        return correct.window_avg, losses.window_avg\n",
    "\n",
    "    def inference(self):\n",
    "        global x\n",
    "        batch_time = AverageMeter()\n",
    "        correct = AverageMeter()\n",
    "        self.model.eval()\n",
    "        end = time.time()\n",
    "        losses = AverageMeter()\n",
    "        for batch_idx, (features, labels) in enumerate(self.val_loader):\n",
    "            prediction = self.model(to_variable(features).float())\n",
    "            loss = self.loss_fn(prediction, to_variable(labels))\n",
    "            losses.update(loss.data.cpu()[0]/features.size(0), features.size(0))\n",
    "            # measure accuracy\n",
    "            curr_correct = self.accuracy(prediction, labels)\n",
    "            correct.update(curr_correct, features.size(0))\n",
    "\n",
    "            #measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "            x.append(prediction.data.cpu().numpy())\n",
    "            if batch_idx == 0:\n",
    "                continue\n",
    "            if batch_idx % self.args.val_display_interval == 0:\n",
    "                info = '[{0}/{1}]\\tTime {batch_time:2.2f}m\\tAcc {val_acc.val:.4f}[{val_acc.avg:.4f}]\\tLoss {losses.val:.4f}[{losses.avg:.4f}]'.format(\n",
    "                      batch_idx,\n",
    "                      len(self.val_loader),\n",
    "                      batch_time=batch_time.sum / 60,\n",
    "                      val_acc=correct,\n",
    "                      losses=losses)\n",
    "                log.info(info)\n",
    "        return correct.avg, losses.avg\n",
    "    \n",
    "    def produce_test(self, res, epoch):\n",
    "        a = []\n",
    "        for d in df.groupby(['order']):\n",
    "            record = d[1].sort_values(['ct'])\n",
    "            m = (record['time'].iloc[0].strftime('%Y%m%d'), record['time'].iloc[0].strftime('%H'))\n",
    "            a.append(m)\n",
    "        nn = np.vstack(x).argmax(-1)\n",
    "        a = pd.DataFrame(a, columns=['date','hour'])\n",
    "        a['pred'] = nn\n",
    "        a.to_csv('stupid_weng.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exec\n",
    "Here is the place we execute our deep learning network. The loss function is CrossEntropyLoss, which is popular in classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train size: 3928, val size: 3928\n",
      "begin training...\n",
      "Epoch: [0][100/246]\tTime 0.63m\tLoss 0.0693[0.0496]\tAcc 0.3750[0.7275]\n",
      "Epoch: [0][200/246]\tTime 1.20m\tLoss 0.0485[0.0453]\tAcc 0.6562[0.6900]\n",
      "[50/123]\tTime 0.16m\tAcc 0.5938[0.5153]\tLoss 0.0289[0.0371]\n",
      "[100/123]\tTime 0.32m\tAcc 0.5312[0.5507]\tLoss 0.0372[0.0349]\n",
      " * epoch [0]:\ttrain_loss 0.0425\ttrain_acc 0.8025\tval_loss 0.0350\tval_acc 0.5532\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved output/model_1526085933_0.8025.t7, best_acc is 0.802500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: [1][100/246]\tTime 0.58m\tLoss 0.0407[0.0466]\tAcc 0.7500[0.6863]\n",
      "Epoch: [1][200/246]\tTime 1.13m\tLoss 0.0410[0.0413]\tAcc 0.9375[0.8025]\n",
      "[50/123]\tTime 0.16m\tAcc 0.4062[0.5870]\tLoss 0.0342[0.0326]\n",
      "[100/123]\tTime 0.32m\tAcc 0.4688[0.5254]\tLoss 0.0397[0.0338]\n",
      " * epoch [1]:\ttrain_loss 0.0397\ttrain_acc 0.8363\tval_loss 0.0342\tval_acc 0.5193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved output/model_1526086039_0.8363.t7, best_acc is 0.836250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: [2][100/246]\tTime 0.62m\tLoss 0.0524[0.0416]\tAcc 0.8438[0.7913]\n",
      "Epoch: [2][200/246]\tTime 1.19m\tLoss 0.0402[0.0397]\tAcc 0.7500[0.8175]\n",
      "[50/123]\tTime 0.16m\tAcc 0.4062[0.5766]\tLoss 0.0306[0.0322]\n",
      "[100/123]\tTime 0.33m\tAcc 0.5312[0.5266]\tLoss 0.0374[0.0325]\n",
      " * epoch [2]:\ttrain_loss 0.0436\ttrain_acc 0.7913\tval_loss 0.0328\tval_acc 0.5224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved output/model_1526086150_0.7913.t7, best_acc is 0.836250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: [3][100/246]\tTime 0.62m\tLoss 0.0615[0.0433]\tAcc 0.5625[0.7350]\n",
      "Epoch: [3][200/246]\tTime 1.28m\tLoss 0.0398[0.0400]\tAcc 0.8438[0.8325]\n",
      "[50/123]\tTime 0.21m\tAcc 0.5312[0.5558]\tLoss 0.0286[0.0328]\n",
      "[100/123]\tTime 0.37m\tAcc 0.4688[0.5427]\tLoss 0.0354[0.0318]\n",
      " * epoch [3]:\ttrain_loss 0.0435\ttrain_acc 0.7650\tval_loss 0.0320\tval_acc 0.5446\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved output/model_1526086271_0.7650.t7, best_acc is 0.836250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: [4][100/246]\tTime 0.66m\tLoss 0.0377[0.0437]\tAcc 0.9375[0.7087]\n",
      "Epoch: [4][200/246]\tTime 1.30m\tLoss 0.0396[0.0409]\tAcc 0.6562[0.8287]\n",
      "[50/123]\tTime 0.16m\tAcc 0.5938[0.5453]\tLoss 0.0295[0.0331]\n",
      "[100/123]\tTime 0.32m\tAcc 0.4688[0.5424]\tLoss 0.0353[0.0318]\n",
      " * epoch [4]:\ttrain_loss 0.0394\ttrain_acc 0.8213\tval_loss 0.0320\tval_acc 0.5448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved output/model_1526086387_0.8213.t7, best_acc is 0.836250\n"
     ]
    }
   ],
   "source": [
    "x = []\n",
    "def main(args):\n",
    "    loader = get_dataloaders(args, BlockDataset, raw_dev_data, raw_dev_label)\n",
    "    model = CNN(in_channels=9, num_classes=5)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = args.lr, weight_decay=args.wd)\n",
    "    scheduler = StepLR(optimizer, step_size=5, gamma=0.6)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    trainer = Trainer(model, optimizer, scheduler, loss_fn, loader, args)\n",
    "    trainer.run(args.epochs)\n",
    "\n",
    "main(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM\n",
    "In order to get to know how well our system is, we write following code, and try to predict using SVM, the result shows that, our model is much higher than SVM, which should be brought by cnn as detector and the non-linearity of neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prediction of SVM is :  0.41\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf = SVC()\n",
    "clf.fit(raw_dev_data[:-100].reshape(-1, 795*9), raw_dev_label[:-100])\n",
    "res = clf.predict(raw_dev_data[-100:].reshape(-1, 795*9))\n",
    "print('The prediction of SVM is : ', np.mean(res == raw_dev_label[-100:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization\n",
    "\n",
    "After extracted all these features and predicted the result, we built a visualization demo system to better present our results.\n",
    "\n",
    "### Features and Encoding\n",
    "\n",
    "We used 9 features to train our predict model. Some of them are encoded with the color shade, for example, darker color represents larger value in quantity; Some are inherently encoded like the area of census tracts; Some are adjustable by dragging slider bars, such as time and hour. Finally the predicted alert level is encoded by both colors and lengths;\n",
    "\n",
    "### Examples\n",
    "\n",
    "Below we provide a couple of demo examples of the visualization. Generally, the map in the middle shows the distributions of features and the bar on the right show the current alert level at the given time. Users can change the time with two sliders on the bottom, which represent date and hour respectively.\n",
    "\n",
    "Firstly, by clicking different feature buttons, the map will display correspondingly. \n",
    "\n",
    "![user density](https://image.ibb.co/grm28y/688_1.png)\n",
    "\n",
    "Currently it shows the user density and we can change it to show the speed of cars.\n",
    "\n",
    "![speed](https://image.ibb.co/kgwDFd/688_2.png)\n",
    "\n",
    "Also we can see the result of different day and hours, by dragging the slider bars.\n",
    "\n",
    "![time](https://image.ibb.co/jCizoy/688_3.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Future work\n",
    "\n",
    "First, as you may notice, the data we collected is quite sparse which limits our prediction. Therefore we want to find other data sources with richer content so that we can predict the traffic alert level with smaller geographic granularity. \n",
    "\n",
    "Second, although we have tried some different metrics already, the features we chose to train and to predict could be further pruned. And with more data we collect, more hidden correlation may be revealed by this kind of attempts.\n",
    "\n",
    "Besides, some alternate learning methods, like GAN, RNN, are also worth trying to optimizing our results. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_python3)",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
